{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('../input/train_labels.csv')\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "train_path = '../input/train/'\n",
    "test_path = '../input/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c1436696254390a3191ed10d01950d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='(220025 images)', max=1, style=ProgressStylâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify Outliers \n",
    "import os\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm_notebook # display a progress bar \n",
    "\n",
    "dark_thres = 10 / 255      # If no pixel reaches this threshold, image is considered too dark \n",
    "bright_thres = 245 / 255   # If no pixel is under this threshold, image is considerd too bright\n",
    "too_dark_idx = []\n",
    "too_bright_idx = []\n",
    "\n",
    "for i, idx in tqdm_notebook(enumerate(data['id']), '({} images)'.format(len(data))):\n",
    "    img_path = os.path.join(train_path, idx)\n",
    "    imagearray = (ndimage.imread(img_path + '.tif')/255).reshape(-1,3) # Normalized to 0~1\n",
    "    # is this too dark\n",
    "    if(imagearray.max() < dark_thres):\n",
    "        too_dark_idx.append(idx)\n",
    "    # is this too bright\n",
    "    if(imagearray.min() > bright_thres):\n",
    "        too_bright_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "data = data.set_index('id')\n",
    "data = data.drop(labels=too_dark_idx, axis=0)\n",
    "data = data.drop(labels=too_bright_idx, axis=0)\n",
    "\n",
    "train_names = data.index.values\n",
    "train_labels = np.asarray(data['label'].values)\n",
    "train_dict = {'id':  train_names, 'label': train_labels}\n",
    "train_data = pd.DataFrame(data=train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176014, 44004)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting data into train and validation\n",
    "train_samples, validation_samples = train_test_split(train_data, stratify=train_data.label, test_size=0.2)\n",
    "len(train_samples), len(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Image Augmentation ###########\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "cols = 96\n",
    "rows = 96\n",
    "\n",
    "#    RANDOM_ROTATION = 5 # range (0-180), 180 allows all rotation variations, 0=no change\n",
    "\n",
    "def random_rotation(img,RANDOM_ROTATION = 5):\n",
    "    #random rotation\n",
    "    rotation = np.random.randint(-RANDOM_ROTATION,RANDOM_ROTATION)\n",
    "    M = cv2.getRotationMatrix2D((48,48),rotation,1)   # the center point is the rotation anchor\n",
    "    img = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return img\n",
    "def random_translation(img, RANDOM_TRANS = 5):\n",
    "    #random x, y translation\n",
    "    transX, transY = np.random.randint(-RANDOM_TRANS, RANDOM_TRANS, 2)\n",
    "    M = np.float32([[1,0,transX],[0,1,transY]])\n",
    "    img = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return img\n",
    "def random_contrast_and_brightness(img, RANDOM_CONTRAST = 0.02, RANDOM_BRIGHTNESS = 0.03):\n",
    "    # random contrast and brightness \n",
    "    random_contrast = 1+np.random.uniform(-RANDOM_CONTRAST,RANDOM_CONTRAST)\n",
    "    random_bright = np.random.uniform(-RANDOM_BRIGHTNESS,RANDOM_BRIGHTNESS)\n",
    "    img = img*random_contrast +random_bright\n",
    "    img= np.clip(img,0,1.0)\n",
    "    return img\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Python generator function\n",
    "def generator(samples, batch_size=64, aug_flag=True):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        samples_df = samples.set_index('id')\n",
    "        img_ids = samples_df.index.values\n",
    "        img_labels = np.asarray(samples_df['label'].values)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = img_ids[offset:offset+batch_size]\n",
    "            batch_labels = img_labels[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            labels = []\n",
    "            for batch_sample, batch_label in zip(batch_samples,batch_labels):\n",
    "                image = ndimage.imread(train_path+batch_sample+'.tif')\n",
    "                image = image /255.0\n",
    "                images.append(image)\n",
    "                labels.append(batch_label)\n",
    "                if aug_flag:\n",
    "                    # flip horizontally\n",
    "                    image = np.fliplr(image)\n",
    "                    images.append(image)\n",
    "                    labels.append(batch_label)\n",
    "                    # flip vertically\n",
    "                    image = np.flipud(image)\n",
    "                    images.append(image)\n",
    "                    labels.append(batch_label)\n",
    "                    # random rotation\n",
    "                    image =random_rotation(image)\n",
    "                    images.append(image)\n",
    "                    labels.append(batch_label)\n",
    "                    # random translation\n",
    "                    image = random_translation(image)\n",
    "                    images.append(image)\n",
    "                    labels.append(batch_label)\n",
    "                    # random contrast and brightness\n",
    "                    image = random_contrast_and_brightness(image)\n",
    "                    images.append(image)\n",
    "                    labels.append(batch_label)\n",
    "                \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(labels)\n",
    "            yield shuffle(X_train, y_train)                \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation generator\n",
    "batch_size = 64\n",
    "train_generator = generator(train_samples, batch_size,aug_flag=True)\n",
    "validation_generator = generator(validation_samples, batch_size,aug_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import keras functions\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, Lambda\n",
    "from keras.layers import Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "######### CNN from Scratch #######################\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "## Convolutional Layer 1 \n",
    "model.add(Conv2D(32,kernel_size = (3,3), strides=(1,1),padding='same', input_shape =(96,96,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "## Convolutional Layer 2 \n",
    "model.add(Conv2D(64,kernel_size = (3,3), strides=(1,1),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "## Convolutional Layer 3 \n",
    "model.add(Conv2D(128,kernel_size = (3,3), strides=(1,1),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "## Convolutional Layer 4 \n",
    "model.add(Conv2D(256,kernel_size = (3,3), strides=(1,1),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "## Convolutional Layer 5\n",
    "model.add(Conv2D(512,kernel_size = (3,3), strides=(1,1),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Flatten())\n",
    "## Full-connected Layer 1\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "## Output Layer \n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,753,729\n",
      "Trainable params: 2,751,233\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify loss functions, optimizer, and metrics\n",
    "import keras\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(0.001), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the best model \n",
    "checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "### Stop training when val_loss has stopped improving\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')\n",
    "\n",
    "### Stream epoch results to a csv file\n",
    "csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=2750, validation_data=<generator..., validation_steps=687, verbose=1, callbacks=[<keras.ca..., epochs=8)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750/2750 [==============================] - 954s 347ms/step - loss: 0.3085 - acc: 0.8716 - val_loss: 0.2880 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28803, saving model to model.h5\n",
      "Epoch 2/8\n",
      "2750/2750 [==============================] - 921s 335ms/step - loss: 0.2124 - acc: 0.9177 - val_loss: 0.2724 - val_acc: 0.8937\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28803 to 0.27239, saving model to model.h5\n",
      "Epoch 3/8\n",
      "2750/2750 [==============================] - 911s 331ms/step - loss: 0.1789 - acc: 0.9326 - val_loss: 0.8647 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27239\n",
      "Epoch 4/8\n",
      "2750/2750 [==============================] - 910s 331ms/step - loss: 0.1580 - acc: 0.9414 - val_loss: 0.7378 - val_acc: 0.7961\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27239\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f092eb6f898>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit_generator(train_generator, steps_per_epoch=len(train_samples)//batch_size, \\\n",
    "                    validation_data=validation_generator,validation_steps=len(validation_samples)//batch_size, \\\n",
    "                    nb_epoch=8,verbose=1,callbacks = [checkpoint,earlystop,csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Predict training labels\n",
    "train_samples_df = train_samples.set_index('id')\n",
    "img_ids = train_samples_df.index.values\n",
    "y_train_true = np.asarray(train_samples_df['label'].values)\n",
    "y_train_pred = []\n",
    "for idx in img_ids:\n",
    "    image = ndimage.imread(train_path+idx+'.tif')\n",
    "    predicted_label = model.predict(np.expand_dims(image/255.0, axis=0))[0][0]\n",
    "    y_train_pred.append(predicted_label)\n",
    "y_train_pred = np.asarray(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score for training set is 0.9037307389404272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Training auc-roc score\n",
    "# Compute false positive rate and  true positive rate\n",
    "fpr, tpr, _ = roc_curve(y_train_true, y_train_pred)\n",
    "\n",
    "# Compute ROC-AUC score\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('ROC-AUC score for training set is {}'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Predict validation labels\n",
    "\n",
    "val_samples_df = validation_samples.set_index('id')\n",
    "img_ids = val_samples_df.index.values\n",
    "y_val_true = np.asarray(val_samples_df['label'].values)\n",
    "y_val_pred = []\n",
    "for idx in img_ids:\n",
    "    image = ndimage.imread(train_path+idx+'.tif')\n",
    "    predicted_label = model.predict(np.expand_dims(image/255.0, axis=0))[0][0]\n",
    "    y_val_pred.append(predicted_label)\n",
    "y_val_pred = np.asarray(y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score for validation set is 0.9004382701138233\n"
     ]
    }
   ],
   "source": [
    "# Validation auc-roc score\n",
    "# Compute false positive rate and  true positive rate\n",
    "fpr, tpr, _ = roc_curve(y_val_true, y_val_pred)\n",
    "\n",
    "# Compute ROC-AUC score\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('ROC-AUC score for validation set is {}'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 0 - 5000\n",
      "Indexes: 5000 - 10000\n",
      "Indexes: 10000 - 15000\n",
      "Indexes: 15000 - 20000\n",
      "Indexes: 20000 - 25000\n",
      "Indexes: 25000 - 30000\n",
      "Indexes: 30000 - 35000\n",
      "Indexes: 35000 - 40000\n",
      "Indexes: 40000 - 45000\n",
      "Indexes: 45000 - 50000\n",
      "Indexes: 50000 - 55000\n",
      "Indexes: 55000 - 60000\n"
     ]
    }
   ],
   "source": [
    "from glob import glob \n",
    "import os\n",
    "\n",
    "# Test set submissions\n",
    "test_files = glob(os.path.join(test_path,'*.tif')) #find the test file names\n",
    "submission = pd.DataFrame() #create a dataframe to hold results\n",
    "file_batch = 5000 #we will predict 5000 images at a time\n",
    "max_idx = len(test_files) #last index to use\n",
    "for idx in range(0, max_idx, file_batch): #iterate over test image batches\n",
    "    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]}) #add the filenames to the dataframe\n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) #add the ids to the dataframe\n",
    "    test_df['image'] = test_df['path'].map(ndimage.imread) #read the batch\n",
    "    images = np.stack(test_df.image, axis=0) #convert to numpy array\n",
    "    predicted_labels = [model.predict(np.expand_dims(image/255.0, axis=0))[0][0] for image in images]\n",
    "    predictions = np.array(predicted_labels)\n",
    "    test_df['label'] = predictions\n",
    "    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])  \n",
    "submission.to_csv(\"submission.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d3a0e75dd14a12773d7ad53bda6f1e1c5ba97f5c</td>\n",
       "      <td>0.516965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bdb69de941bb1dedf3d15564b39a67dec276f701</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371816c763c118a62ac1f4139f45806167c7e88b</td>\n",
       "      <td>0.022199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d18e5df26368164b4cd531941e489f2f19a5302d</td>\n",
       "      <td>0.010909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d57c22c04cd9c20540edff394de0f50fcdf55d0d</td>\n",
       "      <td>0.900185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id     label\n",
       "0  d3a0e75dd14a12773d7ad53bda6f1e1c5ba97f5c  0.516965\n",
       "1  bdb69de941bb1dedf3d15564b39a67dec276f701  0.000176\n",
       "2  371816c763c118a62ac1f4139f45806167c7e88b  0.022199\n",
       "3  d18e5df26368164b4cd531941e489f2f19a5302d  0.010909\n",
       "4  d57c22c04cd9c20540edff394de0f50fcdf55d0d  0.900185"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(5) #display first 5 lines    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
